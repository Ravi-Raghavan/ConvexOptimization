{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #4 - Ravi Raghavan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Vanilla Gradient Descent Algorithm\n",
    "#f: function\n",
    "#gradient: function that computes gradient of f at particular point\n",
    "#x0: initial starting point\n",
    "#alpha: fixed step size\n",
    "#max_iter: maximum number of iterations to run\n",
    "#epislon: converge criterion for function value\n",
    "def vanilla_gradient_descent(f, gradient, x0: np.ndarray, alpha, max_iter, epsilon):\n",
    "    x = x0\n",
    "    fx = f(x)\n",
    "    \n",
    "    print(f\"Initial Function Value: {fx}\")\n",
    "    function_values = []\n",
    "    function_values.append(fx)\n",
    "    points = np.array([x])\n",
    "    \n",
    "    for iter in range(max_iter):\n",
    "        x = x - alpha * gradient(x)\n",
    "        points = np.append(points, x[np.newaxis, :, :], axis=0)\n",
    "        \n",
    "        print(f\"Updated Function Value: {f(x)}\")\n",
    "        \n",
    "        if np.abs(f(x) - fx) <= epsilon:\n",
    "            break\n",
    "        \n",
    "        fx = f(x)\n",
    "        function_values.append(fx)\n",
    "    \n",
    "    function_values = np.array(function_values)\n",
    "    return points, function_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Line Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_line_search_gradient_descent(f, gradient, exact_line_search, x0: np.ndarray, max_iter, epsilon):\n",
    "    x = x0\n",
    "    fx = f(x)\n",
    "    \n",
    "    print(f\"Initial Function Value: {fx}\")\n",
    "    function_values = []\n",
    "    function_values.append(fx)\n",
    "    points = np.array([x])\n",
    "    \n",
    "    for iter in range(max_iter):\n",
    "        grad = gradient(x)\n",
    "        alpha = exact_line_search(f, x, -1 * grad)\n",
    "        x = x - alpha * gradient(x)\n",
    "        points = np.append(points, x[np.newaxis, :, :], axis=0)\n",
    "        \n",
    "        print(f\"Updated Function Value: {f(x)}\")\n",
    "        \n",
    "        if np.abs(f(x) - fx) <= epsilon:\n",
    "            break\n",
    "        \n",
    "        fx = f(x)\n",
    "        function_values.append(fx)\n",
    "    \n",
    "    function_values = np.array(function_values)\n",
    "    return points, function_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtracking Line Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
