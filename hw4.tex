\documentclass{article}

\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

%=====================================================
% Add PACKAGES Here (You typically would not need to):
%=====================================================

\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amsthm}
\usepackage{fancyhdr}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{algorithmic}
\usepackage{algorithm}

\usepackage{amsmath, amssymb}  % Include the amsmath and amssymb packages for mathematical symbols

%=====================================================
% Ignore This Part (But Do NOT Delete It:)
%=====================================================

\theoremstyle{definition}
\newtheorem{problem}{Problem}
\newtheorem*{fun}{Fun with Algorithms}
\newtheorem*{challenge}{Challenge Yourself}
\def\fline{\rule{0.75\linewidth}{0.5pt}}
\newcommand{\finishline}{\begin{center}\fline\end{center}}
\newtheorem*{solution*}{Solution}
\newenvironment{solution}{\begin{solution*}}{{\finishline} \end{solution*}}
\newcommand{\grade}[1]{\hfill{\textbf{($\mathbf{#1}$ points)}}}
\newcommand{\thisdate}{February 29, 2024}
\newcommand{\thissemester}{\textbf{Rutgers: Spring 2024}}
\newcommand{\thiscourse}{ECE 509: Convex Optimization} 
\newcommand{\thishomework}{Number} 
\newcommand{\thisname}{Name} 
\newcommand{\thisextension}{Yes/No} 

\headheight 40pt              
\headsep 10pt
\renewcommand{\headrulewidth}{0pt}
\pagestyle{fancy}

\newcommand{\thisheading}{
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { \textbf{\thiscourse \hfill \thissemester} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Homework \#\thishomework \hfill} }
       \vspace{2mm}
         \hbox to 6.28in { { \hfill \thisdate  \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { \emph{Name: \thisname \hfill Extension: \thisextension}}
      \vspace{2mm}}
      }
   \end{center}
   \bigskip
}

%=====================================================
% Some useful MACROS (you can define your own in the same exact way also)
%=====================================================


\newcommand{\ceil}[1]{{\left\lceil{#1}\right\rceil}}
\newcommand{\floor}[1]{{\left\lfloor{#1}\right\rfloor}}
\newcommand{\prob}[1]{\Pr\paren{#1}}
\newcommand{\expect}[1]{\Exp\bracket{#1}}
\newcommand{\var}[1]{\textnormal{Var}\bracket{#1}}
\newcommand{\set}[1]{\ensuremath{\left\{ #1 \right\}}}
\newcommand{\poly}{\mbox{\rm poly}}


%=====================================================
% Fill Out This Part With Your Own Information:
%=====================================================


\renewcommand{\thishomework}{4} %Homework number
\renewcommand{\thisname}{Ravi Raghavan} % Enter your name here
\renewcommand{\thisextension}{No} % Pick only one of the two options accordingly

\begin{document}

\thisheading
\vspace{-0.75cm}


%=====================================================
% LaTeX Tip: You can erase this part from here.... 
%=====================================================		

\finishline

%=====================================================
% LaTeX Tip: ... to here
%=====================================================	


\bigskip

\begin{problem} 

    
\end{problem}

\begin{problem} \textit{Backtracking Line Search} Suppose $f$ is strongly convex with $mI \preceq \nabla^2f(x) \preceq MI$. Let $\Delta x$ be a descent direction at $x$. Show that the backtracking stopping condition holds for

\begin{equation}
                        \label{eq:example}
                            0 < t \leq -\frac{\nabla f(x)^T \Delta x}{M ||\Delta x||^2_2}
                    \end{equation}

Use this to give an upper bound on the number of backtracking iterations. 

\begin{solution} Let's briefly revisit the backtracking algorithm 

\begin{algorithm}
\caption{Backtracking}
\begin{algorithmic} 
\STATE Parameters: $\Delta x$(Given Descent Direction for $f$ at $x \in dom f$) , $\alpha \in (0, 0.5)$, $\beta \in (0, 1)$
\STATE $t = 1$

\WHILE{$f(x + t\Delta x) > f(x) + \alpha t\nabla f(x)^T \Delta x$}
\STATE {$t = \beta t$ } 
\ENDWHILE

\end{algorithmic}
\end{algorithm}

Based on the definition of strong convexity, we know that \newline 
\begin{equation}
    \label{eq:example}
        f(y) \leq f(x) + \nabla f(x)^T (y - x) + \frac{M}{2} ||y - x||^2_2
\end{equation}

Hence, if we set $y = x + t\Delta x$ 
\begin{equation}
    \label{eq:example}
        f(x + t\Delta x) \leq f(x) + \nabla f(x)^T (x + t\Delta x - x) + \frac{M}{2} ||x + t\Delta x - x||^2_2
\end{equation}

\begin{equation}
    \label{eq:example}
        f(x + t\Delta x) \leq f(x) + t\nabla f(x)^T (\Delta x) + \frac{Mt^2}{2} ||\Delta x||^2_2
\end{equation}

Backtracking Stopping Condition: $f(x + t\Delta x) \leq f(x) + \alpha t\nabla f(x)^T (\Delta x)$ \newline 
Due to the definition of strong convexity, we are guaranteed for this backtracking stopping condition to hold when: \newline 
$f(x) + \alpha t\nabla f(x)^T (\Delta x) \geq f(x) + t\nabla f(x)^T (\Delta x) + \frac{Mt^2}{2} ||\Delta x||^2_2$ 

$\alpha t\nabla f(x)^T (\Delta x) \geq t\nabla f(x)^T (\Delta x) + \frac{Mt^2}{2} ||\Delta x||^2_2$

$0 \geq (1 - \alpha) t \nabla f(x)^T (\Delta x) + \frac{Mt^2}{2} ||\Delta x||^2_2$

$0 \geq t[(1 - \alpha) \nabla f(x)^T (\Delta x) + \frac{Mt}{2} ||\Delta x||^2_2]$

We must have $t > 0$ AND $(1 - \alpha) \nabla f(x)^T (\Delta x) + \frac{Mt}{2} ||\Delta x||^2_2 \leq 0$

$(1 - \alpha) \nabla f(x)^T (\Delta x) + \frac{Mt}{2} ||\Delta x||^2_2 \leq 0$ \newline 

$\frac{Mt}{2} ||\Delta x||^2_2 \leq (\alpha - 1) \nabla f(x)^T (\Delta x)$ \newline 

$t \leq \frac{2(\alpha - 1) \nabla f(x)^T (\Delta x)}{M||\Delta x||^2_2}$ \newline 



Since $\alpha \in (0, 0.5)$, we can see that $\frac{2(\alpha - 1) \nabla f(x)^T (\Delta x)}{M||\Delta x||^2_2} < -\frac{\nabla f(x)^T \Delta x}{M ||\Delta x||^2_2}$ \newline 

Hence, we see that $0 < t \leq -\frac{\nabla f(x)^T \Delta x}{M ||\Delta x||^2_2}$

Let $t_1 = -\frac{\nabla f(x)^T \Delta x}{M ||\Delta x||^2_2}$ \newline
For an upper bound on the number of backtracking iterations, we need: \newline 
$\beta^k \leq t_1$ \newline
$k \geq \log _{\beta}(t_1)$ \newline

\end{solution}
\end{problem}

\begin{problem}
    
\end{problem}

\end{document}





