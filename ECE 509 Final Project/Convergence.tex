\subsection{Convergence for Strongly Convex and Smooth Functions}
\noindent \textbf{Theorem.} Let us say that we have a function $f$ that is both a Sum of $L-$Smooth Functions and a Sum of Convex Functions. We will also assume that $f$ is $p$ strongly convex. Let us say that the sequence of iterates generated by the SGD Algorithm is $(x^{(t)})_{t \in \mathbb{N}}$ and we will assume that we have a constant stepsize satisfying $0 < \gamma < \frac{1}{2L_{max}}$. Then, we can say that for each iteration(i.e. $t \geq 0$) 
\begin{equation}
    \mathbb{E}||x^{(t)} - x^*||^2 \leq (1 - \gamma p)^t ||x^{(0)} - x^*||^2 + \frac{2 \gamma}{p} \sigma_f^*
\end{equation}

\noindent \textbf{Proof:} \newline 
We know that, in Stochastic Gradient Descent, our iterates progress as such: $x^{(t + 1)}  = x^{(t)} - \gamma \nabla f_{i_t}(x^{(t)})$ \newline 

$||x^{(t)} - x^*||^2 = ||x^{(t - 1)} - \gamma \nabla f_{i_t}(x^{(t - 1)}) - x^*||^2$ \newline 

$||x^{(t)} - x^*||^2 = ||x^{(t - 1)} - x^* - \gamma \nabla f_{i_t}(x^{(t - 1)})||^2$ \newline 


$||x^{(t)} - x^*||^2 = ||x^{(t - 1)} - x^*||^2 - 2\langle x^{(t - 1)} - x^*,  \gamma \nabla f_{i_t}(x^{(t - 1)})\rangle + ||\gamma \nabla f_{i_t}(x^{(t - 1)})||^2$

$||x^{(t)} - x^*||^2 = ||x^{(t - 1)} - x^*||^2 - 2\langle x^{(t - 1)} - x^*,  \gamma \nabla f_{i_t}(x^{(t - 1)})\rangle + \gamma^2 ||\nabla f_{i_t}(x^{(t - 1)})||^2$

Now, let's take the Expectation conditioned on $x^{(t + 1)}$ \newline 
$\mathbb{E}||x^{(t)} - x^*||^2 = ||x^{(t - 1)} - x^*||^2 - 2\gamma \langle x^{(t - 1)} - x^*,  \nabla f(x^{(t - 1)})\rangle + \gamma^2 \mathbb{E} ||\nabla f_{i_t}(x^{(t - 1)})||^2$ \newline 


Based on the definition of strong convexity, we know that $f(y) \geq f(x) + \nabla(f(x))^T (y - x) + \frac{p}{2} ||y - x||^2_2$ \newline 


This would mean that $f(x^*) \geq f(x^{(t - 1)}) + \nabla(f(x^{(t - 1)}))^T (x^* - x^{(t - 1)}) + \frac{p}{2} ||x^* - x^{(t - 1)}||^2_2$ \newline 


$f(x^*) \geq f(x^{(t - 1)}) + \nabla(f(x^{(t - 1)}))^T (x^* - x^{(t - 1)}) + \frac{p}{2} ||x^* - x^{(t - 1)}||^2_2$ \newline 


$\nabla(f(x^{(t - 1)}))^T (x^{(t - 1)} - x^*) \geq f(x^{(t - 1)}) - f(x^*) + \frac{p}{2} ||x^{(t - 1)} - x^*||^2_2$ \newline 

We can substitute this into the earlier equation we derived and get: \newline 

$\mathbb{E}||x^{(t)} - x^*||^2 = ||x^{(t - 1)} - x^*||^2 - 2\gamma \langle x^{(t - 1)} - x^*,  \nabla f(x^{(t - 1)})\rangle + \gamma^2 \mathbb{E} ||\nabla f_{i_t}(x^{(t - 1)})||^2 \leq ||x^{(t - 1)} - x^*||^2 - 2\gamma (f(x^{(t - 1)}) - f(x^*) + \frac{p}{2} ||x^{(t - 1)} - x^*||^2_2) + \gamma^2 \mathbb{E} ||\nabla f_{i_t}(x^{(t - 1)})||^2$ \newline 

Let's try to simplify $||x^{(t - 1)} - x^*||^2 - 2\gamma (f(x^{(t - 1)}) - f(x^*) + \frac{p}{2} ||x^{(t - 1)} - x^*||^2_2) + \gamma^2 \mathbb{E} ||\nabla f_{i_t}(x^{(t - 1)})||^2$ \newline 

$||x^{(t - 1)} - x^*||^2 - 2\gamma (f(x^{(t - 1)}) - f(x^*)) - p \gamma ||x^{(t - 1)} - x^*||^2_2 + \gamma^2 \mathbb{E} ||\nabla f_{i_t}(x^{(t - 1)})||^2$ \newline 


$(1 - p \gamma)||x^{(t - 1)} - x^*||^2 - 2\gamma (f(x^{(t - 1)}) - f(x^*))+ \gamma^2 \mathbb{E} ||\nabla f_{i_t}(x^{(t - 1)})||^2$ \newline 

$\mathbb{E}||x^{(t)} - x^*||^2  \leq (1 - p \gamma)||x^{(t - 1)} - x^*||^2 - 2\gamma (f(x^{(t - 1)}) - f(x^*))+ \gamma^2 \mathbb{E} ||\nabla f_{i_t}(x^{(t - 1)})||^2$ \newline 

Earlier, we proved that, when we have a function that is a sum of $L-$ Smooth functions and that is a sum of convex functions, $\mathbb{E}[||\nabla f_i(x)||^2] \leq 4L_{max} (f(x) - \inf f) + 2 \sigma_f^*$ \newline 

We can continue on with our proof as such: \newline 

$\mathbb{E}||x^{(t)} - x^*||^2  \leq (1 - p \gamma) \mathbb{E}||x^{(t - 1)} - x^*||^2 - 2\gamma(f(x^{(t - 1)}) - f(x^*)) + \gamma^2 (4L_{max} (f(x^{(t - 1)}) - \inf f) + 2 \sigma_f^*)$ \newline 

$\mathbb{E}||x^{(t)} - x^*||^2  \leq (1 - p \gamma) \mathbb{E}||x^{(t - 1)} - x^*||^2 + (2 \gamma) (2 \gamma L_{max} - 1)(f(x^{(t - 1)}) - f(x^*)) + 2\gamma^2 \sigma_f^*$ \newline 

$\mathbb{E}||x^{(t)} - x^*||^2  \leq (1 - p \gamma) \mathbb{E}||x^{(t - 1)} - x^*||^2 + (2 \gamma) (2 \gamma L_{max} - 1) \mathbb{E}(f(x^{(t - 1)}) - f(x^*)) + 2\gamma^2 \sigma_f^*$ \newline 

Since $\gamma < \frac{1}{2L_{max}}$, $2\gamma L_{max} - 1 < 0$. We also know that $\mathbb{E}(f(x^{(t - 1)}) - f(x^*)) > 0$ Hence \newline 

$\mathbb{E}||x^{(t)} - x^*||^2  \leq (1 - p \gamma) \mathbb{E}||x^{(t - 1)} - x^*||^2 + (2 \gamma) (2 \gamma L_{max} - 1) \mathbb{E}(f(x^{(t - 1)}) - f(x^*)) + 2\gamma^2 \sigma_f^* \leq (1 - p \gamma) \mathbb{E}||x^{(t - 1)} - x^*||^2 + 2\gamma^2 \sigma_f^*$ \newline 


$\mathbb{E}||x^{(t)} - x^*||^2  \leq (1 - p \gamma) \mathbb{E}||x^{(t - 1)} - x^*||^2 + 2\gamma^2 \sigma_f^*$ \newline 

Let's build this inequality recursively and see how it unfolds: \newline 
$\mathbb{E}||x^{(1)} - x^*||^2  \leq (1 - p \gamma) ||x^{(0)} - x^*||^2 + 2\gamma^2 \sigma_f^*$ \newline 

$\mathbb{E}||x^{(2)} - x^*||^2  \leq (1 - p \gamma) \mathbb{E}||x^{(1)} - x^*||^2 + 2\gamma^2 \sigma_f^*$ \newline 

$\mathbb{E}||x^{(2)} - x^*||^2  \leq (1 - p \gamma) ((1 - p \gamma) ||x^{(0)} - x^*||^2 + 2\gamma^2 \sigma_f^*) + 2\gamma^2 \sigma_f^*$ \newline 


We can see that $\mathbb{E}||x^{(t)} - x^*||^2 \leq (1 - \gamma p)^t ||x^{(0)} - x^*||^2 + \sum_{n=0}^{t - 1} (1 - p\gamma)^n 2\gamma^2 \sigma_f^*$

Let's look at the term $\sum_{n=0}^{t - 1} (1 - p\gamma)^n 2\gamma^2 \sigma_f^*$. 

$\sum_{n=0}^{t - 1} (1 - p\gamma)^n 2\gamma^2 \sigma_f^* < \sum_{n=0}^{\infty} (1 - p\gamma)^n 2\gamma^2 \sigma_f^* = \frac{1}{p\gamma} 2\gamma^2 \sigma_f^* = \frac{2\gamma \sigma_f^*}{p}$

Hence, we can see that \newline 
$\mathbb{E}||x^{(t)} - x^*||^2 \leq (1 - \gamma p)^t ||x^{(0)} - x^*||^2 + \sum_{n=0}^{t - 1} (1 - p\gamma)^n 2\gamma^2 \sigma_f^* \leq (1 - \gamma p)^t ||x^{(0)} - x^*||^2 + \frac{2 \gamma}{p} \sigma_f^*$

$\mathbb{E}||x^{(t)} - x^*||^2 \leq (1 - \gamma p)^t ||x^{(0)} - x^*||^2 + \frac{2 \gamma}{p} \sigma_f^*$
