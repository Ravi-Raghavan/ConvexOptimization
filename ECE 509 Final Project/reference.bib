@INPROCEEDINGS{IntroSGD,
  author={Newton, David and Pasupathy, Raghu and Yousefian, Farzad},
  booktitle={2018 Winter Simulation Conference (WSC)}, 
  title={RECENT TRENDS IN STOCHASTIC GRADIENT DESCENT FOR MACHINE LEARNING AND BIG DATA}, 
  year={2018},
  volume={},
  number={},
  pages={366-380},
  keywords={Optimization;Tutorials;Stochastic processes;Complexity theory;Machine learning;Inference algorithms;Portfolios},
  doi={10.1109/WSC.2018.8632351}}


@InProceedings{Convergence,
  title = 	 {On the Convergence of Stochastic Gradient Descent with Adaptive Stepsizes},
  author =       {Li, Xiaoyu and Orabona, Francesco},
  booktitle = 	 {Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics},
  pages = 	 {983--992},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
  volume = 	 {89},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {16--18 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v89/li19c/li19c.pdf},
  url = 	 {https://proceedings.mlr.press/v89/li19c.html},
  abstract = 	 {Stochastic gradient descent is the method of choice for large scale optimization of machine learning objective functions. Yet, its performance is greatly variable and heavily depends on the choice of the stepsizes. This has motivated a large body of research on adaptive stepsizes. However, there is currently a gap in our theoretical understanding of these methods, especially in the non-convex setting. In this paper, we start closing this gap: we theoretically analyze in the convex and non-convex settings a generalized version of the AdaGrad stepsizes. We show sufficient conditions for these stepsizes to achieve almost sure asymptotic convergence of the gradients to zero, proving the first guarantee for generalized AdaGrad stepsizes in the non-convex setting. Moreover, we show that these stepsizes allow to automatically adapt to the level of noise of the stochastic gradients in both the convex and non-convex settings, interpolating between O(1/T) and O(1/sqrt(T)), up to logarithmic terms.}
}

@article{BookonOptimizer,
  title={Stochastic gradient descent},
  author={Ketkar, Nikhil and Ketkar, Nikhil},
  journal={Deep learning with Python: A hands-on introduction},
  pages={113--132},
  year={2017},
  publisher={Springer}
}


@InProceedings{Stability,
  title = 	 {Train faster, generalize better: Stability of stochastic gradient descent},
  author = 	 {Hardt, Moritz and Recht, Ben and Singer, Yoram},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1225--1234},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/hardt16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/hardt16.html},
  abstract = 	 {We show that parametric models trained by a stochastic gradient method (SGM) with few iterations have vanishing generalization error. We prove our results by arguing that SGM is algorithmically stable in the sense of Bousquet and Elisseeff. Our analysis only employs elementary tools from convex and continuous optimization. We derive stability bounds for both convex and non-convex optimization under standard Lipschitz and smoothness assumptions. Applying our results to the convex case, we provide new insights for why multiple epochs of stochastic gradient methods generalize well in practice. In the non-convex case, we give a new interpretation of common practices in neural networks, and formally show that popular techniques for training large deep models are indeed stability-promoting. Our findings conceptually underscore the importance of reducing training time beyond its obvious benefit.}
}

@misc{garrigos2024handbook,
      title={Handbook of Convergence Theorems for (Stochastic) Gradient Methods}, 
      author={Guillaume Garrigos and Robert M. Gower},
      year={2024},
      eprint={2301.11235},
      archivePrefix={arXiv},
      primaryClass={math.OC}
}

@article{yousefian2012stochastic,
  title={On stochastic gradient and subgradient methods with adaptive steplength sequences},
  author={Yousefian, Farzad and Nedi{\'c}, Angelia and Shanbhag, Uday V},
  journal={Automatica},
  volume={48},
  number={1},
  pages={56--67},
  year={2012},
  publisher={Elsevier}
}